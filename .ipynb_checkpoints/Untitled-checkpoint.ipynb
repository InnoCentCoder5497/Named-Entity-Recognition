{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_vocabularies, load_dataset\n",
    "\n",
    "DATA_PATH = \"Data/ner_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of sentences : 47959\n"
     ]
    }
   ],
   "source": [
    "sentences, tags = load_dataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sentences, \n",
    "                                                    tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TOKEN = '<unk>'\n",
    "PAD_WORD_TOKEN = '<pad>'\n",
    "PAD_TAG_TOKEN = '<pad_tag>'\n",
    "\n",
    "word_vocab, tag_vocab = create_vocabularies(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size : 31985\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size : {len(word_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset:\n",
    "    def __init__(self, vocab_dict, tag_dict, sent_list, tag_list):\n",
    "        self.vocab = vocab_dict\n",
    "        self.tags = tag_dict\n",
    "        \n",
    "        self.sentences = sent_list\n",
    "        self.sentence_tags = tag_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sent = self.sentences[idx]\n",
    "        tags = self.sentence_tags[idx]\n",
    "        \n",
    "        psent = [self.vocab.get(word, self.vocab[UNK_TOKEN]) for word in sent]\n",
    "        ptags = [self.tags.get(tag) for tag in tags]\n",
    "        \n",
    "        return torch.LongTensor(psent), torch.LongTensor(ptags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sentences, tags = map(list, zip(*batch))\n",
    "    max_len = max([len(x) for x in sentences])\n",
    "    \n",
    "    bsent = torch.zeros([len(batch), max_len], dtype = torch.long)\n",
    "    btags = torch.zeros([len(batch), max_len], dtype = torch.long)\n",
    "    \n",
    "    for i in range(len(batch)):\n",
    "        bsent[i, :] = F.pad(sentences[i], (0, max_len - len(sentences[i])), 'constant', word_vocab[PAD_WORD_TOKEN])\n",
    "        btags[i, :] = F.pad(tags[i], (0, max_len - len(tags[i])), 'constant', tag_vocab[PAD_TAG_TOKEN])\n",
    "    \n",
    "    return bsent, btags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = NERDataset(word_vocab, tag_vocab, X_train, y_train)\n",
    "test_data = NERDataset(word_vocab, tag_vocab, X_test, y_test)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dl = DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, out_size):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, out_size)\n",
    "        self.logSoftmax = nn.LogSoftmax(dim = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ex = self.embedding(x)\n",
    "        out, _ = self.lstm(ex)\n",
    "        out = out.view(-1, out.shape[2])\n",
    "        out = self.output(out)\n",
    "        \n",
    "        return self.logSoftmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word_vocab)\n",
    "OUT_SIZE = len(tag_vocab) - 1\n",
    "EMB_SIZE = 300\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, label):\n",
    "    label = label.view(-1)\n",
    "    \n",
    "    mask = (label >= 0).float()  # Mask for pad tag tokens i.e. -1\n",
    "    \n",
    "    label = label % outputs.shape[1] # because indexing with -ve number is \n",
    "                                     # not desired\n",
    "        \n",
    "    num_tokens = torch.sum(mask)  # number of tokens to be counted in loss\n",
    "    \n",
    "    # we have log likelihood, we are calculating NLLL by neglecting Pad tokens\n",
    "    return -torch.sum(outputs[range(outputs.shape[0]), label] * mask) / num_tokens\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    labels = labels.ravel()\n",
    "    \n",
    "    mask = (labels >= 0)\n",
    "    \n",
    "    outputs = np.argmax(outputs, axis = 1)\n",
    "    \n",
    "    return np.sum(outputs == labels) / float(np.sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LSTMNet(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, OUT_SIZE)\n",
    "opt = optim.Adam(net.parameters(), lr=1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Training Loss : 0.763 Accuracy : 83.786\n",
      "Testing Loss : 0.416 Accuracy : 89.314\n",
      "Epoch : 2\n",
      "Training Loss : 0.326 Accuracy : 91.117\n",
      "Testing Loss : 0.298 Accuracy : 92.658\n",
      "Epoch : 3\n",
      "Training Loss : 0.227 Accuracy : 94.208\n",
      "Testing Loss : 0.255 Accuracy : 94.070\n",
      "Epoch : 4\n",
      "Training Loss : 0.187 Accuracy : 95.244\n",
      "Testing Loss : 0.253 Accuracy : 94.349\n",
      "Epoch : 5\n",
      "Training Loss : 0.172 Accuracy : 95.580\n",
      "Testing Loss : 0.255 Accuracy : 94.510\n",
      "Epoch : 6\n",
      "Training Loss : 0.164 Accuracy : 95.696\n",
      "Testing Loss : 0.261 Accuracy : 94.574\n",
      "Epoch : 7\n",
      "Training Loss : 0.159 Accuracy : 95.807\n",
      "Testing Loss : 0.269 Accuracy : 94.623\n",
      "Epoch : 8\n",
      "Training Loss : 0.157 Accuracy : 95.836\n",
      "Testing Loss : 0.279 Accuracy : 94.615\n",
      "Epoch : 9\n",
      "Training Loss : 0.155 Accuracy : 95.849\n",
      "Testing Loss : 0.292 Accuracy : 94.551\n",
      "Epoch : 10\n",
      "Training Loss : 0.154 Accuracy : 95.862\n",
      "Testing Loss : 0.300 Accuracy : 94.567\n"
     ]
    }
   ],
   "source": [
    "net = net.cuda()\n",
    "\n",
    "\n",
    "\n",
    "for k in range(10):\n",
    "    train_l = 0\n",
    "    train_a = 0\n",
    "    \n",
    "    test_l = 0\n",
    "    test_a = 0\n",
    "    \n",
    "    for j, (sbatch, tbatch) in enumerate(dl):\n",
    "        sbatch = sbatch.cuda()\n",
    "        tbatch = tbatch.cuda()\n",
    "        out_pred = net(sbatch)\n",
    "        \n",
    "        l = loss_fn(out_pred, tbatch)\n",
    "\n",
    "        l.backward()\n",
    "        train_l += l.item()\n",
    "        opt.step()\n",
    "        \n",
    "        out = out_pred.data.cpu().numpy()\n",
    "        tout = tbatch.data.cpu().numpy()\n",
    "        train_a += accuracy(out, tout)\n",
    "    print(f\"Epoch : {k + 1}\")\n",
    "    print(f\"Training Loss : {train_l / j:.3f} Accuracy : {train_a * 100 / j:.3f}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k, (sbatch, tbatch) in enumerate(test_dl):\n",
    "            sbatch = sbatch.cuda()\n",
    "            tbatch = tbatch.cuda()\n",
    "            \n",
    "            out_pred = net(sbatch)\n",
    "            \n",
    "            l = loss_fn(out_pred, tbatch)\n",
    "            \n",
    "            test_l += l.item()\n",
    "            \n",
    "            out = out_pred.data.cpu().numpy()\n",
    "            tout = tbatch.data.cpu().numpy()\n",
    "            test_a += accuracy(out, tout)\n",
    "    \n",
    "    print(f\"Testing Loss : {test_l / k:.3f} Accuracy : {test_a * 100 / k:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = dict(zip(word_vocab.values(), word_vocab.keys()))\n",
    "idx2tag = dict(zip(tag_vocab.values(), tag_vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence : 1\n",
      "Merck\twithdrew\tthe\tpopular\tdrug\tlast\tyear\tafter\ta\tstudy\tshowed\tit\tdoubled\tthe\trisk\tof\theart\tproblems\tin\tlong-term\tusers\t.\n",
      "Truth Labels\n",
      "B-org\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "Predictions\n",
      "B-org\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "\n",
      "\n",
      "\n",
      "Sentence : 2\n",
      "French\tForeign\tMinister\tPhilippe\tDouste-Blazy\tsaid\tFriday\the\thopes\tIran\twill\thear\tthe\tvoice\tof\treason\tand\tnot\tresume\tnuclear\tactivities\t.\n",
      "Truth Labels\n",
      "B-org\tI-org\tO\tB-per\tI-per\tO\tB-tim\tO\tO\tB-geo\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "Predictions\n",
      "B-gpe\tO\tI-per\tB-per\tI-per\tO\tB-tim\tO\tO\tB-geo\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\n",
      "\n",
      "\n",
      "\n",
      "Sentence : 3\n",
      "Meanwhile\t,\tChina\thas\treported\ttwo\tnew\toutbreaks\tof\tbird\tflu\tamong\tpoultry\tin\tthe\tnortheastern\tprovince\tof\tLiaoning\t,\tbringing\tthe\ttotal\tnumber\tof\treported\toutbreaks\tin\tthe\tcountry\tover\tthe\tpast\tmonth\tto\tsix\t.\n",
      "Truth Labels\n",
      "O\tO\tB-geo\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-geo\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-tim\tO\tB-tim\tI-tim\tO\n",
      "Predictions\n",
      "O\tO\tB-geo\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-geo\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-tim\tO\tO\tO\tO\n",
      "\n",
      "\n",
      "\n",
      "Sentence : 4\n",
      "The\tWFP\tissued\ta\tstatement\tearly\tThursday\t,\tsaying\tunidentified\tpirates\tboarded\tthe\tfreighter\tMV\tSemlow\toff\tthe\tcoast\tof\tSomalia\tearlier\tthis\tweek\t.\n",
      "Truth Labels\n",
      "O\tB-org\tO\tO\tO\tO\tB-tim\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-geo\tO\tO\tO\tO\n",
      "Predictions\n",
      "O\tB-org\tO\tO\tO\tO\tB-tim\tO\tO\tO\tO\tO\tO\tO\tB-org\tB-art\tO\tO\tO\tO\tB-geo\tO\tO\tO\tO\n",
      "\n",
      "\n",
      "\n",
      "Sentence : 5\n",
      "However\t,\tsome\tdelegates\tsay\tsuch\ta\tdeal\twould\trequire\tmore\tsignificant\tIsraeli\tconcessions\t.\n",
      "Truth Labels\n",
      "O\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-gpe\tO\tO\n",
      "Predictions\n",
      "O\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tO\tB-gpe\tO\tO\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = torch.argmax(out_pred, axis = 1)\n",
    "out = out.reshape(tbatch.shape[0], -1)\n",
    "\n",
    "sentences = sbatch[:5].data.cpu().numpy()\n",
    "labels = tbatch[:5].data.cpu().numpy()\n",
    "preds = out[:5].data.cpu().numpy()\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Sentence : {}\".format(i + 1))\n",
    "    sent = sentences[i]\n",
    "    label = labels[i]\n",
    "    pred = preds[i]\n",
    "    \n",
    "    temp = (label >= 0).sum()\n",
    "    \n",
    "    sent = list(map(lambda x: idx2word.get(x, idx2word[1]), sent[:temp]))\n",
    "    sent = '\\t'.join(word for word in sent if word != '<pad>')\n",
    "    \n",
    "    label = list(map(lambda x: idx2tag.get(x, idx2tag[-1]), label[:temp]))\n",
    "    label = '\\t'.join(word for word in label if word != '<pad_tag>')\n",
    "    \n",
    "    pred = list(map(lambda x: idx2tag.get(x, idx2tag[-1]), pred[:temp]))\n",
    "    pred = '\\t'.join(word for word in pred if word != '<pad_tag>')\n",
    "    \n",
    "    print(sent)\n",
    "    print(\"Truth Labels\")\n",
    "    print(label)\n",
    "    print(\"Predictions\")\n",
    "    print(pred)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
